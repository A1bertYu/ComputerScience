#INTRODUCTION TO ALGORITHM
second edition 潘金贵译 机械工业出版社
##第2章 算法入门
###Insertion sort
伪码  

	INSERTION_SORT(A)
	for j = 2 to n
		key = A[j]
		i = j-1
		while(A[i] > key && i > 0)
			A[i+1] = A[i]
			--i
		A[i+1] = A[j]

循环不变式（loop invariant）  
三个步骤，分别对应循环前，循环中和循环后：  
（1）初始化：先证明第一轮迭代之前，循环不变式是成立的；  
（2）保持：每一轮循环都能使循环不变式保持成立。  
（3）终止：循环结束后，证明循环不变式成立。  
上述所谓的循环不变式，是指与循环有关的某个变量（如已排序数组），在每次循环后，性质保持不变。例如，对于插入排序，每一次循环后产生的已排序的子数组，其称循环不变式。  
循环不变式与数学归纳法是很相似的，前两步一样，第三步前者是到循环结束（有限），后者则是归纳到无穷（无限）。  
插入排序是增量（incremental）方法，即在已排序的子数组中，将后续元素插入，形成最后的结果。
插入排序是**原地排序**，即在排序输入数组时，只有常数个元素被存放到数组以外的空间中去。
###算法分析
>一般来说，算法所需时间是与输入规模同步增长的，因而常常将一个程序的运行时间表示为其输入的函数。这就要求对术语“运行时间”和“输入规模”更加仔细地加以定义。（P13）

对于要分析的程序（即算法具体的实现，可以是伪代码），假定其每条语句运行时间为常数（每条语句对应不同常数），并计算出其执行次数（与输入有关），再对所有语句的用时求和，便可进行复杂度分析。算法性能通常与输入有关，且一般是用最坏情况进行衡量。
###算法设计
* 分治法  
将原问题划分成n个规模较小而结构与原问题相似的子问题；递归地解决这些子问题，然后再合并结果，就得到原问题的解。  
分治法在每一层递归中，都包括三个步骤：分解（Divide），解决（Conquer）和合并（Combine）。分解是将原问题分解成一系列子问题；解决是递归地解决各子问题（若子问题足够小，直接求解）；合并是指将子问题的解进行合并而得到原问题的解。
* Merge sort  

		MERGE(A, p, q, r)
		n1 = q - p + 1
		n2 = r - q
		create arrays L[1,...,n1+1] and R[1,...,n2+1]
		for i = 1 to n1
			L[i] = A[p+i-1]
		for j = 1 to n2
			R[j] = A[q+j]
		L[n1+1] = +inf
		R[n2+1] = +inf
		i = 1, j = 1
		for k = p to r
			if L[i] <= R[j]
				A[k] = L[i++]
			else
				A[k] = R[j++]
对于上述合并，有两点值得注意：（1）**哨兵元素的使用**，这样避免尾部的检测（若不使用，需要比较i或者j是否到达了n1或者n2，这样每一次循环多了两次比较）；（2）循环的设计，设计为一次循环就完成A数组的求取，这种情况下其实不用担心L或者R越界的。（1）是（2）的基础，有了（1）之后才能设计（2）的循环。  
有一种容易想到的解法是用while循环，来确保L，R不越界，在循环体内比较L和R的元素之后再赋值给数组，退出循环之后再将没有遍历完的数组赋值给数组A。该解法其实在每次循环都检测了尾部，多做了一次比较工作（L和R是否越界n1和n2，而此处所列解法只需判断是否越界r），因此不及此处所列解法。	

		Merge sort
		MERGE_SORT(A, p, r)
			if p < r
				q = floor((p + r)/2)
				MERGE_SORT(A, p, q)
				MERGE_SORT(A, q+1, r)
				MERGE(A, p, q, r)	
**理解递归**：对于合并排序中的递归，可以这么理解，递归调用时，最开始是直达底层，底层的整个函数处理完后（如本例中的两次合并排序递归再合并），再返回至上一层的递归调用处，沿着该处继续处理这一层的语句，若在这一层的后续中又遇递归，则又是直达底层，继而依前述流程执行。（可通过观察图2-4的执行过程进行体会学习）有些情况下我们会遇到**尾递归**，尾递归可以理解为一系列的代码展开，只是到达最底层后再逐层上浮。


* 分治法分析  
	根据分治法的特点，其执行时间可以用递归式进行表示**T(n) = aT(n/b) + D(n) + C(n)**, 其中D(n)和C(n)分别表示分解该问题和合并子问题的解的时间，而且在n小于某个值时，T(n)是常数。对比数列的**通项公式**，两者有点类似，可比较学习。
##第3章 函数的增长
渐进记号，定义的是一个集合，此外，其不等式成立的条件类似于证明数量极限时，只有对n > N时才成立。另外，算法性能的函数定义域是自然数集，且为正函数。

##第4章 递归式
在第2章分治法分析中提到了类似与数列通项公式的递归式。该递归式又可以写做：  
>T(n) = aT(n/b) + f(n) 其中，a >= 1, b > 1, f(n)是已知函数。b > 1体现了递归解决的方式是将大问题划归为小问题，这样才能求解，总不能越分越大吧！

关于递归式的解法，本章介绍了代换法、递归树和主定理两种方法。  

* 代换法  
	步骤，先猜测（需要经验甚至创造性），再用数学归纳法去证明。  
	证明时，最后推到出的表达式的结果一定要与猜测的相同，比如，假设T(n) <= cn,那么最后导出的是T(n)<=cn+1，这也是不满足要求的。当然，这样缩放式证明是可以的：T(n) <= cn-1 < cn  
	需要注意的地方是，要避免陷阱，比如T(n) <= cn，证出T(n) <= cn + n并没有得证，因为假设与最后导出的表达式要一致。  
	有些情况也可以使用变量替换法，求出结果后再替换回去。

* 递归树  
	画出一个递归树是一种得到好猜测的直接方法。递归的层数是最先使通项中T(n/b)中的自变量为1的层数（一般在T(c)递归到达底部，c为常数，假定为1与假定为其它常数也只差一个常数项，不影响分析），层数k满足等式power(b, k) = n。观察图4-1，每一层按等比为a进行裂变，直至到最后一层，因此，图4-1最后一层的项数为n*log(b,a)（注意，power(a, log(b,n)) = power(n, log(b, a))，参考3.15式）。

* 主方法（master method）  
	从图4-1递归树中的各层执行时间来看，在最后一层，执行时间已经与f(n)无关，而与power(n, log(b, a))有关，但前面各层的执行时间则与f(n)有关，因此，主方法推导出了三种情况，即根据f(n)与power(n, log(b, a))的关系，T(n)有不同的渐进界。   
	第二种情况递归层数是lgn，所以有该系数  
	第三种情况有个附加条件，来历可以参考图4-3  
	多项式小于（polynomially smaller），差一个power(n, epsilon)因子，epsilon为某大于0的常数。
##第5章 概率分析和随机算法
###雇佣问题
均匀的随机排列，对于n个元素的数组，其有n!种出现的次序，若每一种次序出现的概率都相同，则称为均匀的随机排列。
###指示器随机变量
首先回顾一下概率论的一些基本定义。  
**随机试验**：（1）可以在相同的条件下重复进行；（2）每次试验的可能结果不止一个，并且能事先明确试验的所有可能结果；（3）进行一次试验之前不能确定哪一个结果会出现。  
**样本空间**：随机试验E的所有可能结果组成的集合称为E的样本空间，记为S。  
**样本点**：随机试验E的每个结果，称为样本点。  
**随机事件（简称事件）**：样本空间S的子集为随机试验E的随机事件。在每次试验中，当前仅当这一子集中的一个样本点出现时，称这一 **事件发生**。  
**基本事件**：由一个样本点组成的单点集，称为基本事件。  
**随机变量**：设随机变量的样本空间为S={e}（注意：是集合），X=X(e)是定义在样本空间S的单值函数。称X=X(e)为随机变量。例如，X是投掷3次硬币得到正面的次数，在这个试验（投掷硬币3次）中，样本空间S可以确定，X的值也能确定，X的定义域显然是属于S的。对于某随机变量，其值的概率之和为1.  
**指示器随机变量**，关于随机事件A的函数，A发生值为1，A不发生值为0.显然，指示器随机变量的期望等于事件A发生的概率。增加了一层间接性，在寻找问题解决方法时多了一种思路，特别是在分析重复随机试验中的情况时。  
**应用例子**：  
（1）统计抛掷一枚硬币时正面朝上的期望次数。每一次抛掷时也对应一个随机事件，因此可以将每次抛掷的正面朝上事件用指示器随机变量来包装，总次数（也是随机变量）就是各指示器随机变量之和。  
（2）雇佣问题。雇佣新的办公助理的次数，假设应聘者以随机顺序出现，前i个应聘者中的任何一个都等可能的是目前最具资格的，因此，应聘者i被雇佣的概率为1/i，因此，雇佣次数就是所有应聘者被雇佣的期望之和。
###随机算法
许多随机算法通过排列给定的输入数组来使输入随机化。  

* 随机排列数组  
	一种常用的方法是为数组的每个元素A[i]赋予一个随机的的优先级P[i]，然后根据优先级对数组进行排序。  

		PERMUTE_BY_SORTING(A)
		n = length(A)
		for i = 1 to n
			P[i] = Random(1,n^3)
		sort A, using P as sort keys
		return A
	上述伪代码假定所产生的优先级都是唯一的，即数组P元素值各异
	关于上述产生的排列，其属于均匀随机排列的证明，思路是对于任意序列，证明其出现的概率为1/n!，书中对一种特殊情况，即第一个元素最小，第i个元素第i小，进而可以证明。其实，可以这样做更一般的假设，即第i个元素第j小，此时，依旧即该事件为Xi，进而可以得到同样的概率求解式子，只是在进行条件分解时，先分解第1小的，其次再是第2小的，以此类推，这样可以得到与书中特例的相同解1/n!。

		RANDOMIZE_IN_PLACE(A)
		n = length(A)
		for i = 1 to n
			swap(A[i], Random(i, n))
	<font color='red'>证明还有待添加</font>
###概率分析和指示器随机变量的进一步使用
* 生日悖论  
	求房间里的最少人数，使两个人有相同生日的机会超过50%。  
	书中给出了两种解法，都很有参考价值。对于第一种直接使用概率分析的解法，书中是从反面进行了求解，即所有人生日都不相同的概率，并且在通过通项的形式来进行推导，这种角度很值得学习。第二种使用了指示型随机变量，如何合理的设定指示型随机变量也是很有技巧的，书中是将两人生日相同的事件包装成了指示型随机变量（此时变量的意义是生日相同的对数（pair，不是log）），在假设所有人生日都独立，且所有人生日均匀分布在全年各天的情况下，求出两人生日相同的概率为1/n，进而可以求出指示型随机变量的期望，最后求出了生日相同的对数（pair，不是log）的期望，虽然没有按题意解答问题（50%概率），但也看到了另一种思路。
	<font color='blue'>关于该问题的一些思考：第一种解法显然是将生日组合划分成了两块，第一块是生日各不相同，第二块是生日不是各不相同（即两个人或者以上有相同的生日，这也是所要解决的问题），解法一是从反面解决该问题的。第二种解法，最开始以为是与第一种解法类似，只是从正面直接去计算概率（第二块的概率），且以为只考虑了两两相同的部分，而两两相同的部分因为重叠原因，也包括了三个相同四个相同...全部相同，但这样还是多算了，毕竟三个相同等也只是多个两两相同组成的。后来仔细思考了一番，发现理解错了，指示型随机变量虽然是指示的两人生日相同的事件，且其期望是两人生日相同的概率，**但多个指示型随机变量之和并不是概率**，而是两人生日相同这种事件发生的数量，这点一定要理解清楚，若是概率，人数很多时，岂不超过了1？此外，解法二只是求解了这种事件能发生（期望大于1）的人数，而未考虑大于50%的题意要求</font>
* 球与盒子  
	<font color='red'>本小点以及本章后续以后再补充。</font>
##第6章 堆排序
代码紧凑的算法，其运行时间所隐含的常数因子就很小。堆排序综合了插入排序（原地排序，in place）和合并排序（运行时间）的优点。
>堆排序还引入另一种算法设计技术：利用某种数据结构（在此算法中为“堆”）来管理算法执行中的信息。（P73）
###堆
二叉堆数据结构是一种数组对象，它可以被视为一颗完全二叉树。表示堆的数组A具有两个属性：length(A)表示数组中元素的个数，而heap-size(A)表示存放在A中堆的元素个数，而且heap-size(A)小于等于length(A)，A[1...heap-size(A)]中的元素为堆中的元素，其余元素则不是堆中的元素。树的根为A[1]  
		
	PARENT(i)
		return floor(i/2)
	LEFT(i)
		return 2*i
	RIGHT(i)
		return 2*i + 1
二叉堆分大根堆和小根堆，在大根堆中，节点i需要满足的性质是A[PARENT(i)] >= A[i]；小根堆则是A[PARENT(i)] <= A[i]。
###保持堆的性质
	MAX_HEAPIFY(A, i)
	l = LEFT(i)
	r = RIGHT(i)
	largest = i
	if l <= heap-size(A) && A[i] < A[l]
		largest = l
	if r <= heap-size(A) && A[largest] < A[r]
		largest = r
	if largest != i
		swap (A[i], A[largest])
		MAX_HEAPIFY(A, largest)
上述代码通过数组中元素位置，来使得最大堆性质得以保持。关于上述代码的时间分析，元素i肯定与下标比自己大的元素（子女元素）交换（若需要交换的话），随着下标的增大，渐渐的会使得递归返回。那相邻的递归之间运行时间有什么关系呢？通过代码，可以列出通项T(n) = T(n/b) + C，那最坏的情况肯定是b最小的情况，也就是问题规模减少的最少，也就是子树结点数量最大可能的占比，借助图6-2，若是对A[1]进行调整（根结点），且若递归的是左子树（并且图6-2中A[5]要有右子女），此时左子树占比最大6/11，小于2/3，之后的递归不会比6/11大，因此缩放得到书中的递归式。
###建堆	 
	BUILD_MAX_HEAP
	heap-size(A) = length(A)
	for i = floor(length(A) / 2) downto 1
		MAX_HEAPIFY(A, i)
在建堆的过程中，叶结点是不需要管的，因为其没有子结点，无需考虑堆的性质（父结点与子结点关系）。此外，建堆的过程是从下到上来进行建立。  
###堆排序	
	HEAP_SORT
	BUILD_MAX_HEAP
	for i = length(A) to 2
		swap(A[1], A[i])
		heap_size(A) = heap_size(A) - 1
		MAX_HEAPIFY(A, 1)
###优先级队列
最大优先级队列和最小优先级队列。下面对前者进行介绍，包括四个操作：MAXIMUM(S)，EXTRACT_MAX(S)，INCREASE_KEY(S, x, k)和INSERT(S,x)  

* 获取最大值  

		MAXIMUM(A)
		return A[1]
* 去除最大元素	
		
		EXTRACT_MAX(A)
		max = A[1]
		swap(A[1], A[heap-size(A)])
		heap-size(A) = heap-size(A) - 1
		MAX_HEAPIFY(A, 1)
		return max
* 将堆中某元素的值更换为更大的值

		INCREASE_KEY(A, i, key)
		if A[i] > key
			error, key must bigger than the current key
		while (i > 1 && A[Parent(i)] < A[i])
			swap(A[Parent(i)], A[i])
			i = Parent(i)

* 添加元素

		INSERT(A, key)
		heap_size(A) = heap_size(A) + 1
		A[heap_size(A)] = -inf
		INCREASE_KEY(A, heap_size(A), key)
##第7章 快速排序
快排最坏情况运行时间是O(n^2)，期望运行时间是O(nlog(n))，且常数因子较小，通常在实践中优先采用快排。 
###快速排序的描述
		QUICK_SORT(A, p, r)
		if r > p
			q = PARTITION(A, p, r)
			QUICK_SORT(A, p, q-1)
			QUICK_SORT(A, q+1, r)
上述排序算法最重要的是PARTITION(A)的实现，书中的实现如下：  

		PARTITION(A, p, r)
		x = A[r]
		i = p
		for j = p to r-1
			if(A[j] <= x)
				swap(A[i++], A[j])
		swap(A[i], A[r])
		return i
上述PARTITION代码中，主元（pivot element）的选择很为重要。
###快速排序的性能
>快速排序的运行时间与划分是否对称有关，而后者又与选择了哪一个元素来进行划分有关。（P88）

* 最坏情况划分  
	每次划分后，元素全部在主元的某一边，此种情况为最坏情况（最不对称），T(n)=T(n-1) + T(0) + C（可看做一等差数列），其运行时间为O(n^2)。
* 最佳情况划分  
	每次划分后，主元两侧元素一样多（即两边对称），T(n) <= 2T(n/2)+C，其运行时间为O(nlog(n))
* 平衡的划分  
	书中举例了常数比例的划分，9:1和99:1两种情况，运行时间也是O(nlog(n))。  

随机化版本的快排代码如下，  

	RANDOMIZED_QUICKSORT(A, p, r)
	if p < r
		q = RANDOMIZED_PARTITION(A, p, r)
		RANDOMIZED_QUICKSORT(A, p, q-1)
		RANDOMIZED_QUICKSORT(A, q+1, r)

其中，主元的选择是随机在数组中选择一个元素，之后再按之前的PARTITION进行划分，  
		
	RANDOMIZED_PARTITION(A, p, r)
	i = RANDOM(p, r)
	swap(A[i], A[r])
	return PARTITION(A, p, r)

###快速排序的分析
* 最坏情况分析  
	通过放缩法，列出式子7.1，即在每一轮中，找出用时最大的划分，同时猜测T(n) <= cn^2并得证，而我们可以找出运行时间就是n^2的特例，因此可以得到更渐进的运行时间。  
* 期望的运行时间  
	首先书中引理7.1证明了快速排序的运行时间为O(n+X)，其中，n为调用PARTITION的次数，而X则是PARTITION进行比较操作的总次数。关于比较的次数，两个元素之间最多只进行一次比较，且划分之后，主元两侧的元素是不会进行比较的，比如{1,3,2} 4 {7, 9}，4为主元，4前半部分的元素和后半部分的元素不会再进行比较，前半部分只会与前半部分的进行比较，而后半部分只会与后半部分进行比较。书中引入了指数随机变量，用以包装两个元素需要比较的事件。此外，书中对数组A中的元素进行了重命名，即zi表示第i个最小的元素，**注意，这并不是说A中的数组元素依次为z1,z2,z3,...**。同时，书中又定义了集合Zij = {zi,...,zj}。对于任选的两个元素Zi和Zj，其需要比较的概率是在集合Zij中选择zi或者zj做主元的概率，对于其它情况，两个元素不需要进行比较。**在这里，突然跟Zij扯上关系，刚开始感觉有点比较特例化，若zi和zj之间的元素与Zij不一致如何？**后来仔细一想，并且结合7.2式，第一个求和符号确定了i之后，后续的j是从i+1直至n，也就是说zi与zj之间是有距离j-i-1的，这段距离之间填充的元素数量是j-i-1，至于填充的这些元素是否大于zi并小于zj，无关紧要，且将填充元素假设成集合Zij的，产生的结果也是一样的。只要求得Zi与Zj在所有可能的长度中被选做主元的概率，即对于每一个i，分别求长度2,...,n-i+1对应的j（长度计算时包括zi,zj），并进而求的这些长度对应的选中概率，就可求的zi与zj的比较概率。

##第8章 线性时间排序
###排序算法时间的下界
>**比较排序** 可以被抽象成**决策树** 。一颗决策树是一颗满二叉树，表示某排序算法作用于给定输入所做的**所有比较**。（P97）  
>要使排序算法能正确地工作，其必要条件是，n个元素的n!种排列中的每一种都要作为决策树的一个叶子而出现。（P97）

高为h的决策树，叶子数目不会多于2^h，因此n! < 2^h，解得h >= nlog(n)，这表示**比较排序**（最坏情况下）需要比较h次，也就是下界为O(nlog(n)).
###计数排序
计数排序假设输入的n个元素都是介于0到k的整数，当k=O(n)时，计数排序的运行时间为线性O(n+k)。

	COUNTING_SORT(A, B, k)
	for i = 0 to k
		C[i] = 0
	for j = 1 to length(A)
		C[A[j]] = C[A[j]] + 1
	for i = 1 to k
		C[i] = C[i] + C[i-1]
	for j = length(A) to 1
		B[C[A[j]]] = A[j]
		C[A[j]] = C[A[j]] - 1
上述排序的原理，主要是用数组C先记录A中各元素出现的次数，再将次数累积，进而可以求得A中个元素的**位置信息并存入数组C**，且C中各元素记录的是A中对应元素的最大位置，比如C[3] = 5，则表明A中值为3的元素最大的位置是5，若有两个值为3的元素，则位置4也是值为3的元素。因此，在最后一个for循环中，从length(A)开始，是为了让最大位置放置最后出现的元素（对于相同值的元素来说），这样以保证稳定性，即输出数组中的相对次序与它们在输入数组中的次序相同（这一般是对具有相同值的元素来说）。
###基数排序
基数排序首先按最低有效位数字进行排序，对于d位数字，仅需d遍就可以完成排序，若是按最高有效位开始排序，则需要记录很多中间数据，反而不便。

	RADIX_SORT(A, d)
	for i = 1 to d
		do use a stable sort to sort array A on digit i,
上面代码中1表示最低位，d表示最高位。  
引理8.3中，对每一位数字采用计数排序，用时n+k，共d位，则为d(n+k)  
引理8.4中，中文版翻译是不准的，其翻译的是n位数（而英文版是Given n b-bit numbers，而不是Given n b-digit numbers），准确翻译应该是n位二进制数，若不这样指出，引理是不成立的，因为若n位数的进制就大于2^r，r位二进制就根本表示不了，怎么办？此外，该引理讨论了b, r, n的关系对算法的影响。
###桶排序
>当桶排序（bucket sort）的输入符合均匀分布时，即可以以线性时间运行。与计数排序类似，桶排序也对输入作了某种假设，因而运行得很快。具体来说，计数排序假设输入是由一个小范围内的整数构成，而桶排序则假设输入由一个随机过程产生，该过程将元素均匀地分布在区间[0,1)上。（P102）

	BUCKET_SORT(A)
	n = length(A)
	for i = 1 to n
		insert A[i] into B[floor(n*A[i])]
	for i = 0 to n-1
		sort list B[i] with insertion sort
	concatenate the list B[0], ..., B[n-1] together in order
桶排序的复杂度为O(n)，建立在如下假设（或关系），输入均匀分布；或者各个桶尺寸的平方和与总的输入元素数量呈线性关系。
##第9章 中位数和顺序统计学
在一个由n个元素组成的集合中，第i个顺序统计量（order statistic）是该集合中第i小的元素。一个中位数（median）是它所在集合的“中点元素”，不考虑奇偶，中位数可表示为下中位数和上中位数，分别出现在floor[(n+1)/2]和ceiling[(n+1)/2]处（从1开始）。
###最大值和最小值
最大值和最小值的查找需要比较n-1次，是O(n)；若同时查找最大值和最小值，至多floor(3n/2)次比较。将输入数组两两分组，先两者比较，之后较大者跟最大值比较，较小者跟最小值比较，这样一对元素只需比较3次。
###以期望线性时间做选择
	RANDOMIZE_SELECTION(A, p, r, i)
	if p == r
		return p
	q = RANDOMIZED_PARTITION(A, q, r)
	k = q - p + 1
	if i == k
		return A[q]
	else i < k
		return RANDOMIZE_SELECTION(A, p, q-1, i)
	else
		return RANDOMIZE_SELECTION(A, q+1, r, i-k)
此算法的思想与快速排序相同，也是对输入数组进行递归划分，只不过快速排序会递归地处理两边，而此算法只会处理一边，其期望运行时间为O(n)。但最坏运行时间为O(n^2)，每次划分时只有一边有元素。  
在上述算法中，RANDOMIZED_PARTITION以等概率的返回任一元素作为主元，即以1/n的概率返回q值，也就是k取1到n的值的概率是1/n，这样，左右两边的数组长度分别为k-1和n-k，对于不同k值(1 to n)，对应不同长度，这些不同长度的概率是1/n。因此，通过简单的缩放，假定每次都处理两边数组中的较长的那一边，可以按书中所列递归式进行处理。注意，书中利用了指示型随机变量进行分析，因为指示型随机变量用于表示事件发生或没发生，可以认为是一个bool型变量，对不同k值，需要进行叠加，这样才考虑了所有的可能性。若不用随机性变量，每一种可能性1/n，可以直接得到后面的求期望的表达式。
###最坏情况线性时间的选择
该算法最坏情况也是O(n),方法依旧是对输入数组进行递归划分，但要保证每次划分是好的划分。
之所以能够保证每次都是好的划分，是因为选择了恰当的主元。该算法的在每次递归中，都是选择中位数做为主元，这样，每次划分都是最好的划分。  
具体步骤如下：  
（1）将输入数组划分为floor(n/5)组，即每个组5个元素，当n不是5的倍数时，剩下的组成一个组。  
（2）在每个组中，使用插入排序寻找中位数。  
（3）将寻找到的中位数序列，再次进行划分，直至找到整个数组的中位数x  
（4）将x作为主元，对数组进行划分，假设x为第k个元素，则左边有k-1个元素，右边有n-k个元素。  
（5）若i=k，则返回x；若i<k，则递归调用在左边寻找第i个元素；若i>k，则递归调用在右边寻找第i-k个元素。  
**注意**，此算法运行时间的递归表达式中各项的意义需要清楚，文中也分别对各步骤的运行时间给出了表达式。需要注意的是，总的运行时间称为SELECT的时间，用T(n)表示，而T(n)又划分成了两个子问题，单纯的寻找中位数为T(n/5)，寻找第i个统计量缩放为T(7n/10 + 6)。每一层递归中，前者对应步骤3，而有需要借助步骤1和2（为O(n)）；对于后者，则对应步骤5，而需要步骤4（为O(n)）。最开始看感觉步骤3和步骤5不是同一个问题，其实步骤3也是找顺序统计量，为中位数，这样就可以看做一个问题，进而列出了书中通项。<font color='red'>实际程序中这两个应该不是同一类型吧，至少不能调用相同的递归程序，因为步骤(3)肯定要先找到中位数，以来用作主元。</font><font color='blue'>此外，步骤2的运行时间为O(n)，每一个小组的插入排序运行时间可以看做O(1)，总体来说是O(n)，可以与全局的插入排序做一下比较，分析下运行时间不同的原因</font>
##第10章 基本数据结构
###栈和队列
栈和队列都是动态集合。栈后进先出LIFO，队列则是先进先出FIFO。对空栈进行弹出操作，称为下溢；对栈满了再压入，则为上溢。

* 栈操作

		STACK_EMPTY(S)
		if top(S) == 0
		return true
		else
		return false
	上述代码为空栈检查。

		PUSH(S, x)
		top(S) = top(S) + 1
		S[top(S)] = x
	上述代码为入栈(未检查溢出)

		POP(S)
		if STACK_EMPTY(S)
			"error, underflow"
		else
			top(S) = top(S) - 1
			return S[top(S)+1]
	上述代码为出栈

* 队列操作  
	head(Q)为队列的第一个元素，tail(Q)指向新元素被插入的地方。head(Q)=tail(Q)表示队列为空，初始时head(Q)=tail(Q)=1  

		ENQUEUE(Q, x)
		Q[tail(Q)] = x
		if tail(Q) = length(Q)
			tali(Q) = 1
		else
			tail(Q) = tail(Q) + 1
	上述代码为入队(未检查溢出)

		DEQUEUE(Q)
		x = Q(head(Q))
		if head(Q) = length(Q)
			head(Q) = 1
		else
			head(Q) = head(Q) + 1
		return x
	上述代码为出队(未检查溢出)

###链表
>在链表这种数据结构中，各对象按线性顺序排序。链表与数组不同，数组的线性序是由**数组下标决定** 的，而链表中的顺序是由各对象中的**指针所决定**。(P121)

下面代码都是假定链表为双向的和无序的，链表每个元素包含一个关键字域和两个指针域。对于整个链表，还需要一个指针，用于指向链表当前的首部元素，并且在首部元素有变动时需要更新。  
**注意：以下代码都是对指针进行操作。此外，书中都是用[]，而此处用的()，因为()更像函数调用来返回指针。只有对哨兵元素，此处用了[]，以表示不是指针，而是包含了prev,next,key三个成员的元素（对象）**

	LIST_SEARCH(L, k)
	x = head(L)
	while x != NIL && key(x) != k
		x = next(x)
	return x
上述代码为链表的搜索操作，最坏情况运行时间为O(n)
	
	LIST_INSERT(L, x)
	next(x) = head(L)
	if head(L) != NIL
		prev(head(L)) = x
	head(L) = x;
	prev(x) = NIL;
上述代码为链表的插入操作（插入到首部）。

	LIST_DELETE(L, x)
	if prev(x) != NIL
		next(prev(x)) = next(x)
	else
		head(L) = next(x)
	if next(x) != NIL
		prev(next(x)) = prev(x)
哨兵（sentinel）是个哑（dummy）对象，可以简化边界条件，能使代码更加简洁，可以降低算法的常数因子。但哨兵的使用还是因情况而定，比如短链表，使用哨兵后会造成存储的浪费。  
对于双链表，引入哨兵元素nil[L]，其next指向表头，prev指向表尾，同时表尾的next和表头的prev指向nil[L]**此处用了中括号**，如此，双链表成了一个带哨兵的循环双向链表。上述三种操作的对应代码为：

	LIST_SERACH(L, k)
	x = next(nil(L))
	while x != nil(L) && key(x) != k
		x = next(x)
搜索代码

	LIST_INSERT(L, x)
	next(x) = next(nil(L))
	prev(x) = nil(L)
	prev(next(nil(L))) = x
	next(nil(L)) = x
插入到首部的代码

	LIST_DELETE(L, x)
	next(prev(x)) = next(x)
	prev(next(x)) = prev(x)
删除代码
	
###指针和对象的实现
使用数组和数组下标来构造对象和指针。  

* 对象的多重数组表示
	书中使用三维数组对双链表进行了实现，其中，prev中存储的上一个元素的索引，而next则存储下一个元素的索引，若是表头或表尾，则存储一个非有效索引。而第一个元素的索引，则需要一个变量专门保存，以记录链表表头位置。

##第13章 红黑树
红黑树：满足如下红黑性质的二叉查找树，称为红黑树，即：根黑，父红子必黑，叶节点黑，每个结点开头的所有路径具有相同的黑结点数目。

##附录

###B.5
* 几个定义  
**自由树**：一个**连通且无回路**的无向图。  
**森林**：非连通且无回路的无向图。  
**有根树**：一颗自由树，但其有一个与其它点不同的结点，这个特殊的顶点称为树的根。  
**有序树**：子女节点有序的有根树。  
**二叉树**：是定义在有限集上的结构。要么不包括任何结点（称为空树或零树，用NIL表示），要么由三个不相交的结点集构成：根结点，一个称为左子树的二叉树和一个称为右子树的二叉树。  
**二叉树与有序树的关系**：二叉树更严格一点，例如，某结点其只有左子女或者右子女，这两种情况对应两种二叉树，而对有序树来说，这两种情况是不做区分的。  
**位置树**：结点中的子女用不同的正整数标识，若没有结点被标识成整数i，则该结点的第i个子女缺失。  
**K叉树**：每个结点的标识超过k的子女均缺失的位置树。  
**完全k叉树**：所有叶结点都有相同深度，并且所有内部结点度都为k  
**度**：结点x的子女数目称为度。  
**外部结点（叶结点）**：没有子女的结点。  
**内部结点**：非叶结点称为内部结点。  
**深度**：从根结点r到结点x路径的长度称为x的深度（即边数）。  
**高度**：从结点向下至某个叶结点最长简单路径中边的条数。  
**树的高度**：树中结点的最大深度，也是根结点的高度。  
深度和高度不要混淆，两者都是用边数来衡量，且可以理解二者有互补之意，即一个结点在这两个方面不可能同时都很大（好处不能都占，是吧？）。

